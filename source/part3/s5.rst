.. _part3_1:

.. rubric:: Partie 3 | Arbres de recherche

*************************************************************************************************
Partie 3: Questions d'introduction
*************************************************************************************************

Objectifs
=========

A l'issue de cette partie chaque étudiant sera capable de:

* de décrire avec exactitude et précision les concepts d'arbres binaires de recherche et de table de symboles ordonnée;
* de mettre en oeuvre des algorithmes basés sur les arbres de recherche;
* d'évaluer et mettre en oeuvre des représentations classiques d'arbres de recherche;


A lire
=======================================

Livre de référence:

* Chapitres 3.1, 3.2 et 3.3

Calendrier
==========

TODO

Exercices théoriques
====================

.. note::
    Ces exercices sont à préparer pour le mercredi de S5.

Exercice 3.1.1
""""""""""""""

Laquelle des deux implémentations ``SequentialSearchST`` ou ``BinarySearchST`` utiliseriez vous pour une application
qui réalise :math:`10^3` ``put()`` et :math:`10^6` ``get()`` dans un ordre aléatoire? Justifiez.

.. answer::

    For ``SequentialSearchST``

    - Search: :math:`N` (Worst-case), :math:`N/2` (Average-case)
    - Insert: :math:`N` (Worst-case), :math:`N` (Average-case)


    For ``BinarySearchST``

    - Search: :math:`\log(N)` (Worst-case), :math:`\log(N)` (Average-case)
    - Insert: :math:`2N+\ln(N) \in mathcal{O}(n)` (Worst-case), :math:`\ln(N)+2\cdot N/2  \in mathcal{O}(n)` (Average-case)

    (note: the book doesn't consider that the array is copied at each iteration, thus this is the amortized complexity;
    may be a good opportunity to explain what this is to students? == if we double the size of the internal array
    each time there is an overflow, the complexity per element is :math:`mathcal{O}(1)` for the array copy)
    (the 2 factor that appears here is because there are two arrays)

    Let :math:`M` be the initial size of the array before we do the push and get operations. If :math:`M >> 10^3`, the total number of operations is

    .. math::

        \approx 10^3cdotI(M) + 10^6cdotS(M)

    where :math:`I(M)` and :math:`S(M)` are the cost of inserting and searching in an array of size :math:`M`.

    For ``SequentialSearchST`` it gives :math:`10^3M + 10^6M` worst case, :math:`10^3M/2 + 10^6M` average

    For ``BinarySearchST`` it gives :math:`10^3\cdot 2 \cdot M + 10^6\cdot\log(M)` worst case,  :math:`10^3cdotM + 10^6cdot\log(M)` average case.

    Thus ``BinarySearchST`` if :math:`M` is great enough.

Exercice 3.1.2
""""""""""""""

Implémentez la méthode ``floor()`` de ``BinarySearchST``.

.. answer::

    .. code-block:: java

        public Key floor(Key key) {
            //rank returns the position where the key
            //should be if it is added

            //i.e. if keys[loc] == key => it exists, return key
            //     else, return the key just before the location
            //           where the key should be added

            int loc = rank(key);
            if(keys[loc].compareTo(key) == 0)
                return key;
            return keys[loc-1];
        }

Exercice 3.1.3
"""""""""""""""

*Exercice 3.1.24 du livre*.

En supposant que les clefs soient des doubles ou des entiers. Écrivez une version de la recherche binaire qui supposant
une répartition uniforme des clefs va d'abord chercher au début d'un dictionnaire un mot qui commence par une lettre
proche du début d'alphabet.

Plus exactement, si la clef recherchée est :math:`k_x`, et que la plus petite clef est :math:`k_{lo}` et la plus grande
est :math:`k_{hi}`, cherchez d'abord au pourcentile :math:`\lfloor(k_x-k_{lo})/(k_{hi}-k_{lo}) \rfloor * 100` du tableau
et pas au milieu (pourcentile 50) du tableau d'abord.

Implémentez ``InterpolationSearchST`` et comparez celle-ci sur ``FrequencyCounter``.

.. answer::

    On garde tout le même code soure que BinarySearchST (pages 379, 380) et on
    remplace la fonction ``rank`` (p 380) par celle-ci:

    .. code-block:: java

        private int getPos(Integer k, int start, int end) {
            int rng = end - 1 - start;

            if(rng < 0) return start;
            if(rng == 0) return k.compareTo(keys[start]) < 0 ? start : end;

            int k_start = keys[start];
            int k_end   = keys[end-1];

            Double interpol = ( (k - k_start) / (1.0 * (k_end - k_start)));
            interpol = Math.max(0, interpol);
            interpol = Math.min(1, interpol);
            Double ddm = Math.floor(rng * interpol);
            int mid    = start+ ddm.intValue();
            Integer piv = keys[mid];

            int cmp = piv != null ? k.compareTo(piv) : 0;
            if(cmp <  0) return getPos(k, start, mid);
            if(cmp >  0) return getPos(k, mid+1,   end);
            return mid;
        }

    Pdv performances, si on reprend le FrequencyCounter (et qu'on l'adapte pour que
    l'interpolation search soit utilisable) on obtient les résultats suivants:

    - Le comptage des fréquences prend exactement le même temps pour
      BinarySearchST que pour InterpolationSearchST parce que le cout du
      décalage de tous les éléments (:math:`\mathcal{O}(n)`) qui est nécessaire lorsqu'on inclut
      une nouvelle clé dans la structure est largement supérieur au bénéfice
      potentiel de l'interpolation.
    - Même si on ne fait que des queries dans le tableau, on n'observe pas de
      différence de performance importante entre les deux algos (même si on
      pense intuitivement que l'interpolation devrait aller plus vite).


Exercice 3.1.4
"""""""""""""""

*Exercice 3.1.25 du livre*.

Il est très fréquent de tester d'abord la présence d'une clef avant d'ajouter ou modifier l'entrée correspondante. Cela
engendre successivement plusieurs recherches consécutives de la même clef.

L'idée du *caching* est de mémoriser en interne la dernière clef accédée
et de l'utiliser de manière opportuniste si celle-ci est toujours valide.
Modifiez ``BinarySearchST`` pour y intégrer cette idée.

.. answer::

    Simply create the *instance variables* ``lastKey`` and ``lastI`` (for example) and in functions ``get`` and ``put`` check if ``key==lastKey`` if so use ``lastI`` if not call ``lastI=rank(key)`` and `lastKey = key`.

Exercice 3.1.5
""""""""""""""

*Exercice 3.2.31 du livre*.

Écrivez une méthode ``isBST()`` qui prend un ``Node`` comme argument et qui retourne ``true`` si l'argument est la racine
d'un BST, ``false`` sinon (il faut donc vérifier que les propriétés d'un BST sont satisfaites).

Est-ce que vérifier (localement) si pour chaque noeud la propriété *"le fils gauche a une clef inférieure et le fils
droit une clef supérieure"* est suffisant? Si non donnez un contre-exemple.

Quelle est la complexité de votre algorithme ?

.. answer::

    (Solution from page 420 of Alg4s)

    .. code-block:: java

        private boolean isBST()
        {
            return isBST(root, null, null);
        }

        private boolean isBST(Node x, Key min, Key max)
        {
            if (x == null) return true;
            if (min != null && x.key.compareTo(min) <= 0) return false;
            if (max != null && x.key.compareTo(max) >= 0) return false;
            return isBST(x.left, min, x.key) && isBST(x.right, x.key, max);
        }

Exercice 3.1.6
""""""""""""""

*Exercice 3.2.4 du livre*.

Supposons qu'un certain arbre de recherche possède des clefs entre 1 et 10 et que nous cherchions la clef 5.
Quelle(s) séquence(s) ne peut pas correspondre à la séquence des clefs examinées?

* 10,9,8,7,6,5
* 4,10,8,6,5
* 1,10,2,9,3,8,4,7,6,5
* 2,7,3,8,4,5
* 1,2,10,4,8,5

.. answer::

    Seul le d est impossible ca on a 8 qui apparait après 7,3. Or :math:`8 \not\in\left[7,3\right]`

Exercice 3.1.7
""""""""""""""

*Exercice 3.3.33 du livre*.

Écrivez une méthode ``is23()`` dans ``RedBlackBST`` qui vérifie qu'aucun noeud n'est connecté
à deux liens rouges et qu'il n'y a pas de lien rouge vers la droite.
Écrivez aussi une méthode ``isBalanced()`` qui vérifie que tout chemin depuis la racine vers vers un lien null a le
même nombre de liens noirs. Finalement combinez ``isBST(),is23()`` et ``isBalanced()`` pour implémenter ``isRedBlackBST()``.

.. answer::

    .. code-block:: java

        boolean is23() = return is23(root);
        boolean is23(Node h) {
           if (h == null) return true; //empty tree is 23-tree
           if (isRed(h.right)) return false; //if red at the right !is23

           // we are not the root and both node and his left node is red !is23
           if (h != root && isRed(h) && isRed(h.left)) return false;

           //if h is23 all subtree of h is23 too
           return is23(h.left) && is23(h.right);
        }

        //count the number of the black (nBlack) at the most-left path of the tree from the root. If the tree is balanced there is the same number black for all path from root to null nodes
        boolean isBalanced() {
            int nBlack = 0;
            Node h = root;
            while (h != null) {
                if (!isRed(h)) nBlack++;
                h = h.left;
            }
            return isBalanced(root, nBlack);
        }
        boolean isBalanced(Node h, int nBlack) {
            if (h == null) return nBlack == 0;
            if (!isRed(h)) nBlack--;
            return isBalanced(h.left, nBlack) && isBalanced(h.right, nBlack);
        }


        isRedBlackBST() =  isBST() && is23() && isBalanced().

Exercice 3.1.8
""""""""""""""

Comment faire pour énumérer en ordre croissant toutes les clés mémorisées
dans un arbre binaire de recherche ? Quelle est la complexité temporelle de
cette opération ? Justifiez votre réponse.

.. answer::

    Obviously, on fait simplement un parcours *in-order* sur l'arbre. On
implémente celui-ci avec un tour d'Euler. Donc la complexité est connue et est
en :math:`\theta(n)`. Justification intuitive: Comme on doit toujours parcourir tous
les noeuds de l'arbre (3 fois) on ne fait pas mieux qu':math:`\Omega(N)` mais pas pire
que :math:`mathcal{O}(N)` non plus.

Exercice 3.1.9
""""""""""""""

Partant d'un arbre binaire de recherche initialement vide, comment se présente l'arbre
après y avoir inséré les clés 12, 5, 10, 3, 13, 14, 15, 17, 18, 15 ? Pour les mêmes données comment se présenterait
l'arbre finalement obtenu s'il s'agissait d'un 2-3 arbre ?

Cet exemple illustre-t-il les avantages ou inconvénients de ces différentes structures de données ? Pourquoi ?

.. answer::

    For a binary tree:

    .. image:: 9a.png

    For a 2-3 tree

    .. image:: 9b.png

    .. image:: 9c.png



Exercice 3.1.10
"""""""""""""""

Lequel ou lesquels de ces arbres est(sont) red-black? Pour chacun, dessiner la correspondance vers un 2-3 tree
(décrite p432).

.. image:: rbtree.png
    :alt: Arbres

.. answer::

    Seuls les arbres iii et iv sont des red black trees: les autres ne représentent
    pas un 2-3 tree valide.

    1. Pas d'équilibre au niveau des longueurs noires
    2. Pas un 2-3 arbre balancé, et en plus F est à gauche de E (donc même pas un
    BST)
    3. C'est un RBT (obviously !)
    4. Idem

    .. image:: tree_i.png
    .. image:: tree_ii.png
    .. image:: tree_iii.png
    .. image:: tree_iv.png

Exercices sur INGInious
==========================================

.. note::
   Vous devez faire ces exercices pour le mercredi de S7.

1. `Unit tests redblack <https://inginious.info.ucl.ac.be/course/LSINF1121-2016/PART3WriteUnittestsRedBlackTree>`_
2. `QCM Complexite <https://inginious.info.ucl.ac.be/course/LSINF1121-2016/PART3Qcm>`_
3. `QCM Traversal <https://inginious.info.ucl.ac.be/course/LSINF1121-2016/PART3QcmBt>`_
4. `Exercice redblack <https://inginious.info.ucl.ac.be/course/LSINF1121-2016/PART3Rbt>`_
5. `Implémentation de ceil <https://inginious.info.ucl.ac.be/course/LSINF1121-2016/PART3Bst>`_
6. `Implémentation d un iterateur sur un BST <https://inginious.info.ucl.ac.be/admin/LSINF1121-2016/edit/task/PART3OrderedBstIterator>`_
